{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install cloudmesh-common -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report\n",
    "\n",
    "# Algorithms\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from itertools import cycle # Meanshift plotting\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# Clustering preprocessing \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# Clustering postprocessing\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Benchmarking \n",
    "from cloudmesh.common.StopWatch import StopWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "# Data needs to be manually retireved from kaggle with the csv files being renamed accordingly.\n",
    "StopWatch.start(\"Data Preprocessing\")\n",
    "data_dav = pd.read_csv('dav_heart_disease_dataset.csv') # https://www.kaggle.com/johnsmith88/heart-disease-dataset\n",
    "data_sav = pd.read_csv('sve_cardio_dataset.csv', delimiter = ';') # https://www.kaggle.com/sulianova/cardiovascular-disease-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data and target arrays\n",
    "x_dav = data_dav.drop('target', axis = 1)\n",
    "y_dav = data_dav['target']\n",
    "\n",
    "x_sav = data_sav.drop('cardio', axis = 1)\n",
    "y_sav = data_sav['cardio']\n",
    "\n",
    "# Split the data\n",
    "xtrn_dav, xtst_dav, ytrn_dav, ytst_dav = train_test_split(x_dav, y_dav, test_size=0.20, random_state = 0)\n",
    "\n",
    "xtrn_sav, xtst_sav, ytrn_sav, ytst_sav = train_test_split(x_sav, y_sav, test_size=0.20, random_state = 0)\n",
    "\n",
    "# Normalize\n",
    "dav_scaler = StandardScaler()\n",
    "xtrn_dav_n = dav_scaler.fit_transform(xtrn_dav)\n",
    "xtst_dav_n = dav_scaler.transform(xtst_dav)\n",
    "\n",
    "sav_scaler = StandardScaler()\n",
    "xtrn_sav_n = sav_scaler.fit_transform(xtrn_sav)\n",
    "xtst_sav_n = sav_scaler.transform(xtst_sav)\n",
    "\n",
    "StopWatch.stop(\"Data Preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "StopWatch.start(\"dav SVC\")\n",
    "svc_dav = SVC()\n",
    "svc_dav.fit(xtrn_dav_n, ytrn_dav)\n",
    "svc_dav_predict = svc_dav.predict(xtst_dav_n)\n",
    "svc_dav_conf_mat = confusion_matrix(ytst_dav, svc_dav_predict)\n",
    "svc_dav_acc = accuracy_score(ytst_dav, svc_dav_predict)\n",
    "\n",
    "print(\"Dav set\")\n",
    "print(\"Confusion Matrix\\n{}\\n\\nAccuracy\\n{}\\n\".format(svc_dav_conf_mat, svc_dav_acc*100))\n",
    "print(classification_report(ytst_dav,svc_dav_predict))\n",
    "\n",
    "StopWatch.stop(\"dav SVC\")\n",
    "StopWatch.start(\"sav SVC\")\n",
    "\n",
    "svc_sav = SVC()\n",
    "svc_sav.fit(xtrn_sav_n, ytrn_sav)\n",
    "svc_sav_predict = svc_sav.predict(xtst_sav_n)\n",
    "svc_sav_conf_mat = confusion_matrix(ytst_sav, svc_sav_predict)\n",
    "svc_sav_acc = accuracy_score(ytst_sav, svc_sav_predict)\n",
    "\n",
    "print(\"Sav set\")\n",
    "print(\"Confusion Matrix\\n{}\\n\\nAccuracy\\n{}\\n\".format(svc_sav_conf_mat, svc_sav_acc*100))\n",
    "print(classification_report(ytst_sav,svc_sav_predict))\n",
    "\n",
    "StopWatch.start(\"sav SVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest\n",
    "StopWatch.start(\"dav knn\")\n",
    "knn_dav = KNeighborsClassifier(n_neighbors=10)\n",
    "knn_dav.fit(xtrn_dav_n, ytrn_dav)\n",
    "knn_dav_predict = knn_dav.predict(xtst_dav_n)\n",
    "knn_dav_conf_mat = confusion_matrix(ytst_dav, knn_dav_predict)\n",
    "knn_dav_acc = accuracy_score(ytst_dav, knn_dav_predict)\n",
    "\n",
    "print(\"Dav set\")\n",
    "print(\"Confusion Matrix\\n{}\\n\\nAccuracy\\n{}\\n\".format(knn_dav_conf_mat, knn_dav_acc*100))\n",
    "print(classification_report(ytst_dav,knn_dav_predict))\n",
    "\n",
    "StopWatch.stop(\"dav knn\")\n",
    "StopWatch.start(\"sav knn\")\n",
    "\n",
    "knn_sav = KNeighborsClassifier(n_neighbors=10)\n",
    "knn_sav.fit(xtrn_sav_n, ytrn_sav)\n",
    "knn_sav_predict = knn_sav.predict(xtst_sav_n)\n",
    "knn_sav_conf_mat = confusion_matrix(ytst_sav, knn_sav_predict)\n",
    "knn_sav_acc = accuracy_score(ytst_sav, knn_sav_predict)\n",
    "\n",
    "print(\"Sav set\")\n",
    "print(\"Confusion Matrix\\n{}\\n\\nAccuracy\\n{}\\n\".format(knn_sav_conf_mat, knn_sav_acc*100))\n",
    "print(classification_report(ytst_sav,knn_sav_predict))\n",
    "\n",
    "StopWatch.stop(\"sav knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "StopWatch.start(\"dav GaussNBay\")\n",
    "gnb_dav = GaussianNB()\n",
    "gnb_dav.fit(xtrn_dav_n, ytrn_dav)\n",
    "gnb_dav_predict = gnb_dav.predict(xtst_dav_n)\n",
    "gnb_dav_conf_mat = confusion_matrix(ytst_dav, gnb_dav_predict)\n",
    "gnb_dav_acc = accuracy_score(ytst_dav, gnb_dav_predict)\n",
    "\n",
    "print(\"Dav set\")\n",
    "print(\"Confusion Matrix\\n{}\\n\\nAccuracy\\n{}\\n\".format(gnb_dav_conf_mat, gnb_dav_acc*100))\n",
    "print(classification_report(ytst_dav,gnb_dav_predict))\n",
    "\n",
    "StopWatch.stop(\"dav GaussNBay\")\n",
    "StopWatch.start(\"sav GaussNBay\")\n",
    "\n",
    "gnb_sav = GaussianNB()\n",
    "gnb_sav.fit(xtrn_sav_n, ytrn_sav)\n",
    "gnb_sav_predict = gnb_sav.predict(xtst_sav_n)\n",
    "gnb_sav_conf_mat = confusion_matrix(ytst_sav, gnb_sav_predict)\n",
    "gnb_sav_acc = accuracy_score(ytst_sav, gnb_sav_predict)\n",
    "\n",
    "print(\"Sav set\")\n",
    "print(\"Confusion Matrix\\n{}\\n\\nAccuracy\\n{}\\n\".format(gnb_sav_conf_mat, gnb_sav_acc*100))\n",
    "print(classification_report(ytst_sav,gnb_sav_predict))\n",
    "\n",
    "StopWatch.stop(\"sav GaussNBay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Trees\n",
    "StopWatch.start(\"dav decisionTree\")\n",
    "\n",
    "dtre_dav = DecisionTreeClassifier(criterion = 'entropy',random_state=0,max_depth = 6)\n",
    "dtre_dav.fit(xtrn_dav_n, ytrn_dav)\n",
    "dtre_dav_predict = dtre_dav.predict(xtst_dav_n)\n",
    "dtre_dav_conf_mat = confusion_matrix(ytst_dav, dtre_dav_predict)\n",
    "dtre_dav_acc = accuracy_score(ytst_dav, dtre_dav_predict)\n",
    "\n",
    "print(\"Dav set\")\n",
    "print(\"Confusion Matrix\\n{}\\n\\nAccuracy\\n{}\\n\".format(dtre_dav_conf_mat, dtre_dav_acc*100))\n",
    "print(classification_report(ytst_dav,dtre_dav_predict))\n",
    "\n",
    "StopWatch.stop(\"dav decisionTree\")\n",
    "StopWatch.start(\"sav decisionTree\")\n",
    "\n",
    "dtre_sav = DecisionTreeClassifier(criterion = 'entropy',random_state=0,max_depth = 6)\n",
    "dtre_sav.fit(xtrn_sav_n, ytrn_sav)\n",
    "dtre_sav_predict = dtre_sav.predict(xtst_sav_n)\n",
    "dtre_sav_conf_mat = confusion_matrix(ytst_sav, dtre_sav_predict)\n",
    "dtre_sav_acc = accuracy_score(ytst_sav, dtre_sav_predict)\n",
    "\n",
    "print(\"Sav set\")\n",
    "print(\"Confusion Matrix\\n{}\\n\\nAccuracy\\n{}\\n\".format(dtre_sav_conf_mat, dtre_sav_acc*100))\n",
    "print(classification_report(ytst_sav, dtre_sav_predict))\n",
    "\n",
    "StopWatch.stop(\"sav decisionTree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluserting preprocessing\n",
    "StopWatch.start(\"cluster preprocessing\")\n",
    "dav_cluster = scale(x_dav)\n",
    "sav_cluster = scale(x_sav)\n",
    "\n",
    "n_comp_dav = len(np.unique(y_dav))\n",
    "n_comp_sav = len(np.unique(y_sav))\n",
    "\n",
    "pca_dav = PCA(n_components=n_comp_dav).fit_transform(dav_cluster)\n",
    "pca_sav = PCA(n_components=n_comp_sav).fit_transform(sav_cluster)\n",
    "StopWatch.stop(\"cluster preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Means\n",
    "# Code was rewritten into a function to reduce workload associated in visualizing the clustering algorithms\n",
    "def kMeans(data, labels):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(data, labels, test_size=0.30, random_state=0)\n",
    "    KModel = KMeans(n_clusters = 2, random_state = 9).fit(Xtrain, ytrain)\n",
    "    predictions = KModel.predict(Xtest)\n",
    "    \n",
    "    plt.title('Actual Data')\n",
    "    plt.scatter(Xtest[:,0], Xtest[:,1], marker = 'o', s = 10, c = ytest)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title('Predicted')\n",
    "    plt.scatter(Xtest[:,0], Xtest[:,1], marker = 'o', s = 10, c = predictions)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Confusion matrix\\n\", confusion_matrix(ytest, predictions))\n",
    "    print(\"Accuracy\\n\", accuracy_score(ytest, predictions)*100)\n",
    "    print(classification_report(ytest, predictions))\n",
    "    \n",
    "StopWatch.start(\"dav kmeans\")    \n",
    "kMeans(pca_dav, y_dav)\n",
    "StopWatch.stop(\"dav kmeans\")  \n",
    "StopWatch.start(\"sav kmeans\")  \n",
    "kMeans(pca_sav, y_sav)\n",
    "StopWatch.stop(\"sav kmeans\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean-Shift - Implementation in progress\n",
    "def meanShift(data, labels):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(data, labels, test_size=0.30, random_state=0)\n",
    "    bandwidth = estimate_bandwidth(Xtrain, quantile=0.5)\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    ms.fit(Xtrain)\n",
    "\n",
    "    predictions = ms.predict(Xtest)\n",
    "    \n",
    "    plt.title('Actual Data')\n",
    "    plt.scatter(Xtest[:,0], Xtest[:,1], marker = 'o', s = 10, c = ytest)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title('Predicted')\n",
    "    plt.scatter(Xtest[:,0], Xtest[:,1], marker = 'o', s = 10, c = predictions)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Confusion matrix\\n\", confusion_matrix(ytest, predictions))\n",
    "    print(\"Accuracy\\n\", accuracy_score(ytest, predictions)*100)\n",
    "    print(classification_report(ytest, predictions))\n",
    "    \n",
    "StopWatch.start(\"dav meanShift\")    \n",
    "meanShift(pca_dav, y_dav)\n",
    "StopWatch.stop(\"dav meanShift\")  \n",
    "StopWatch.start(\"sav meanShift\")  \n",
    "meanShift(pca_sav, y_sav)\n",
    "StopWatch.stop(\"sav meanShift\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral Clustering\n",
    "def spectralClust(data, labels):\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(data, labels, test_size=0.30, random_state=0)\n",
    "    specCl = SpectralClustering(n_clusters = 2, affinity='nearest_neighbors', assign_labels='kmeans').fit(Xtrain, ytrain)\n",
    "    predictions = specCl.fit_predict(Xtest)\n",
    "    \n",
    "    plt.title('Actual Data')\n",
    "    plt.scatter(Xtest[:,0], Xtest[:,1], marker = 'o', s = 10, c = ytest)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title('Predicted')\n",
    "    plt.scatter(Xtest[:,0], Xtest[:,1], marker = 'o', s = 10, c = predictions)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Confusion matrix\\n\", confusion_matrix(ytest, predictions))\n",
    "    print(\"Accuracy\\n\", accuracy_score(ytest, predictions)*100)\n",
    "    print(classification_report(ytest, predictions))\n",
    "    \n",
    "StopWatch.start(\"dav spectralClust\")    \n",
    "spectralClust(pca_dav, y_dav)\n",
    "StopWatch.stop(\"dav spectralClust\")  \n",
    "StopWatch.start(\"sav spectralClust\")  \n",
    "spectralClust(pca_sav, y_sav)\n",
    "StopWatch.stop(\"sav spectralClust\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWatch.benchmark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
